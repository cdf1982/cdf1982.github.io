{
  "whisperModels": [
    {
      "modelName": "Excellent",
      "internalName": "ggml-medium",
      "description": "Whisper model with very good quality and reasonable performance",
      "quality": 5,
      "speed": 3,
      "recommended-mac": true,
      "recommended-ios": false,
      "modelURL": "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-medium.bin",
      "mlmodelURL" : "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-medium-encoder.mlmodelc.zip"
    },
    {
      "modelName": "Fast",
      "internalName": "ggml-small",
      "description": "Whisper Small model with excellent performance and decent quality",
      "quality": 3,
      "speed": 4,
      "recommended-mac": true,
      "recommended-ios": true,
      "modelURL": "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-small.bin",
      "mlmodelURL" : "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-small-encoder.mlmodelc.zip"
    },
    {
      "modelName": "Basic",
      "internalName": "ggml-base",
      "description": "Whisper Base model with eccelent performance and acceptable quality",
      "quality": 2,
      "speed": 5,
      "recommended-mac": false,
      "recommended-ios": true,
      "modelURL": "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.bin",
      "mlmodelURL" : "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base-encoder.mlmodelc.zip"
    },
    {
      "modelName": "Fastest",
      "internalName": "ggml-tiny",
      "description": "Whisper Tiny model with fastest performance at the cost of fidelity",
      "quality": 1,
      "speed": 5,
      "recommended-mac": false,
      "recommended-ios": false,
      "modelURL": "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-tiny.bin",
      "mlmodelURL" : "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-tiny-encoder.mlmodelc.zip"
    },
  ]
}